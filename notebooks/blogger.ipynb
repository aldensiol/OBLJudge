{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "297360f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c5bbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aldensio/Desktop/Projects/OBLJudge\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24bb1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tools import BloggerCrawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dc7b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "blogger_crawler = BloggerCrawler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "448bcd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "blogs = blogger_crawler.get_all_posts(\"8343013142987416238\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ba20c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Search and Recommendation at Scale - How does it work?',\n",
       " 'published': '2025-08-25T23:36:00-07:00',\n",
       " 'updated': '2025-08-28T23:19:43-07:00',\n",
       " 'content': '<h3 style=\"text-align: justify;\">Introduction&nbsp;</h3><div style=\"text-align: justify;\"><p data-end=\"571\" data-start=\"340\">If you\\'re a \"doom-scroller\" like me, I\\'m sure you\\'ve wondered to yourself, <em data-end=\"463\" data-start=\"415\">\"how does the TikTok algorithm actually work?\"</em> or <em data-end=\"529\" data-start=\"467\">\"why does it feel so personal to my tastes and preferences?\"</em> This blog aims to address exactly that.</p>\\n<p data-end=\"938\" data-start=\"573\">I’ll walk through some of the fundamental concepts behind recommendation systems, provide a high-level overview of each component, and then show how they come together to form the algorithms we all interact with daily. By the end, you should have a clearer sense of how platforms like TikTok, YouTube, or Netflix serve you exactly what you didn’t know you wanted.</p></div><div><h3 style=\"text-align: justify;\">Concepts</h3></div><h4 style=\"text-align: justify;\">Embedding Models</h4><div><p data-end=\"1189\" data-start=\"983\" style=\"text-align: justify;\">First and foremost, we need to understand <strong data-end=\"1059\" data-start=\"1025\">how machines understand things</strong>. When it comes to items, videos, or user behaviour, machines don’t see texts, colours, or emotions. They only understand numbers.</p>\\n<p data-end=\"1608\" data-start=\"1191\" style=\"text-align: justify;\">This is where <strong data-end=\"1225\" data-start=\"1205\">embedding models</strong> come in. An embedding model takes something complex (like the description of a video or a user’s watch history) and represents it as a vector--essentially, a list of numbers in a high-dimensional space. The magic lies in how these numbers capture relationships. For instance, these 4 words can be modelled into vectors: \"king\", \"queen\", \"man\", and \"woman\". Within the vector space that you have built, the distance between the words \"man\" and \"woman\" should be similar to the distance between the words \"king\" and \"queen\". In the same vein, 2 videos about cooking might end up “closer” in vector space than a cooking video and a gaming video.</p><p data-end=\"1608\" data-start=\"1191\" style=\"text-align: justify;\">This is to say, the distance between any 2 vectors represent how similar they are in meaning or context.</p>\\n<p data-end=\"1777\" data-start=\"1610\" style=\"text-align: justify;\">In simpler terms: embeddings are the language that allows recommendation systems to measure similarity and preference in a way that machines can compute efficiently.</p></div><h4 style=\"text-align: justify;\">Vector Databases</h4><div><p data-end=\"1942\" data-start=\"1807\" style=\"text-align: justify;\">Now that everything is represented as vectors, we need a way to store and search through them quickly.&nbsp;</p>\\n<p data-end=\"2265\" data-start=\"1944\" style=\"text-align: justify;\">A vector database is optimised to handle operations like “find me the most similar items to this cat video” at scale. Instead of scanning billions of items one by one, these databases use clever indexing structures (such as approximate nearest neighbour search or <i>ANN</i> for short) to retrieve the most relevant <i>candidates</i> (<i>answers</i>) in milliseconds.</p>\\n<p data-end=\"2540\" data-start=\"2267\" style=\"text-align: justify;\">Think of it like this: if embeddings are the words, the vector database is the dictionary that lets the system look things up. This step is crucial for scalability, since modern recommendation engines deal with massive catalogs of content and millions/billions of users.</p></div><h4 style=\"text-align: justify;\">Retrieval and Ranking Models</h4><div><p data-end=\"2806\" data-start=\"2582\">Once we have a pool of candidates retrieved from the vector database, the system still needs to decide <em data-end=\"2692\" data-start=\"2685\">which</em> items are most likely to capture your attention. This is where <strong data-end=\"2788\" data-start=\"2756\">retrieval and ranking models</strong> come into play.</p>\\n<ul data-end=\"3299\" data-start=\"2808\">\\n<li data-end=\"3040\" data-start=\"2808\">\\n<p data-end=\"3040\" data-start=\"2810\"><strong data-end=\"2830\" data-start=\"2810\">Retrieval models</strong> narrow down the huge universe of possible items into a smaller, more manageable set (say, from billions to a few thousand). They rely on embeddings and similarity to select items that are generally relevant.</p>\\n</li>\\n<li data-end=\"3299\" data-start=\"3041\">\\n<p data-end=\"3299\" data-start=\"3043\"><strong data-end=\"3061\" data-start=\"3043\">Ranking models</strong> then take this candidate set and re-order it with finer granularity. They incorporate additional <i>signals</i>, or <i>features</i>&nbsp;that <b>YOU</b> display: how long you watch, what you skip, your interactions, trending topics, even temporal context (what time of day you’re scrolling).</p>\\n</li>\\n</ul>\\n<p data-end=\"3473\" data-start=\"3301\">This two-stage process ensures that the system is both <strong data-end=\"3369\" data-start=\"3356\">efficient</strong> (retrieving candidates fast) and <strong data-end=\"3419\" data-start=\"3403\">personalised</strong> (ranking them in a way that feels tailored to you).</p></div><h3 style=\"text-align: justify;\">Architecture</h3><h3 style=\"text-align: justify;\"><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEi6u-a2GAdQ4VGYtE8pthy4wTh-UEXZhUL_ijpfHg4bEWLp2KAuzDhLTx76r4k0eE5OrziwR3wAzhCIlzoSc6YEM2vlu3hn4VSLrer7ZxLlNUc7ivK7WB45BfAz90u8PoLP4yWzEiGeWghOJCjCb_3ULf8hLOFWn5kzlukDBv_ko8PdGjteOxlZbiN8ca_p\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"740\" data-original-width=\"1910\" height=\"248\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEi6u-a2GAdQ4VGYtE8pthy4wTh-UEXZhUL_ijpfHg4bEWLp2KAuzDhLTx76r4k0eE5OrziwR3wAzhCIlzoSc6YEM2vlu3hn4VSLrer7ZxLlNUc7ivK7WB45BfAz90u8PoLP4yWzEiGeWghOJCjCb_3ULf8hLOFWn5kzlukDBv_ko8PdGjteOxlZbiN8ca_p=w640-h248\" width=\"640\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><span style=\"font-weight: 400;\">Full Architecture</span></div></h3><h4 style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEiUq2KslheNRPOKuc3bqAdZQRmDgLA6X_0dDTzpAgLrSEvg9-LUq9Ryp8JEm-GU16M1831ARYl-pC0_YKURB5OXrZl9P27yO1eSKvdcKgdCYEm-Y9OkHtgXevenKpMdHhVqckiKCa3H2Vbz5ePxvpDdP7zDlSoVs_Y6CACZnLIuqLn_BYb3UDokvGPYSqIC\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"736\" data-original-width=\"1780\" height=\"264\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEiUq2KslheNRPOKuc3bqAdZQRmDgLA6X_0dDTzpAgLrSEvg9-LUq9Ryp8JEm-GU16M1831ARYl-pC0_YKURB5OXrZl9P27yO1eSKvdcKgdCYEm-Y9OkHtgXevenKpMdHhVqckiKCa3H2Vbz5ePxvpDdP7zDlSoVs_Y6CACZnLIuqLn_BYb3UDokvGPYSqIC=w640-h264\" width=\"640\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><span style=\"font-weight: normal;\">Feature Store</span></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEh18SEZxnffNqdf2R7iXHSAbxWDgo3ZXlwPs7pORtXqbgQluCEvnJOVTCqyQVssee39SRgWX-0oIyMo8z0orPjMfFKhKI6NOtJn1A4YSCKFM-iHOhi1QVyIeevxd7aA1vC-ifkCtfOhdRxqZLk5pjHuvzlDbRxKSHD77-wvS9L_TQamg12grBJ45-2DrCmW\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"706\" data-original-width=\"1746\" height=\"258\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEh18SEZxnffNqdf2R7iXHSAbxWDgo3ZXlwPs7pORtXqbgQluCEvnJOVTCqyQVssee39SRgWX-0oIyMo8z0orPjMfFKhKI6NOtJn1A4YSCKFM-iHOhi1QVyIeevxd7aA1vC-ifkCtfOhdRxqZLk5pjHuvzlDbRxKSHD77-wvS9L_TQamg12grBJ45-2DrCmW=w640-h258\" width=\"640\" /></a></div><span style=\"font-weight: 400;\">Two-Tower Model</span><br /><br /></div></h4><div><h4 style=\"text-align: left;\">Embedding Models (training perspective)</h4><p data-end=\"525\" data-start=\"340\">The embedding model is often jointly trained to map the <strong data-end=\"412\" data-start=\"396\">“user-space”</strong> into the <strong data-end=\"438\" data-start=\"422\">“item-space”</strong> using what’s called a <strong data-end=\"480\" data-start=\"461\">two-tower model</strong> (sometimes referred to as a dual encoder).</p>\\n<ul data-end=\"749\" data-start=\"527\">\\n<li data-end=\"627\" data-start=\"527\">\\n<p data-end=\"627\" data-start=\"529\">One tower encodes the <strong data-end=\"559\" data-start=\"551\">user</strong>: their watch history, likes, clicks, or other behavioral signals.</p>\\n</li>\\n<li data-end=\"749\" data-start=\"628\">\\n<p data-end=\"749\" data-start=\"630\">The other tower encodes the <strong data-end=\"666\" data-start=\"658\">item</strong>: a video, or product, represented by its metadata and content features.</p>\\n</li>\\n</ul>\\n<p data-end=\"948\" data-start=\"751\">Both towers output vectors in the same high-dimensional space. The goal is simple: if User A likes cat videos, then User A’s vector should end up <strong data-end=\"909\" data-start=\"897\">close to</strong> the vector representing a cat video.</p><p data-end=\"991\" data-start=\"950\">The loss function can be thought of as:</p><blockquote data-end=\"1165\" data-start=\"992\">\\n<p data-end=\"1165\" data-start=\"994\">“User A watched a cat video, so let’s pull User A’s vector closer to the cat video’s vector in the embedding space, while pushing it further away from unrelated videos.”</p></blockquote></div><div><h4 style=\"text-align: left;\">Ranking Models (training perspective)</h4>\\n<p data-end=\"1586\" data-start=\"1357\"></p></div><div><p data-end=\"1586\" data-start=\"1357\">Unlike the embedding model, the ranking model is trained in a <strong data-end=\"1565\" data-start=\"1536\">supervised learning setup</strong> with labeled data.</p>\\n<ul data-end=\"1987\" data-start=\"1588\">\\n<li data-end=\"1754\" data-start=\"1588\">\\n<p data-end=\"1754\" data-start=\"1590\"><strong data-end=\"1600\" data-start=\"1590\">Input:</strong> A candidate user-item pair (e.g., “User A and Video X”), along with contextual features like time of day, device type, or whether the item is trending.</p>\\n</li>\\n<li data-end=\"1885\" data-start=\"1755\">\\n<p data-end=\"1885\" data-start=\"1757\"><strong data-end=\"1767\" data-start=\"1757\">Label:</strong> The ground truth engagement signal, such as whether the user actually clicked, watched, how long he watched, liked, or skipped the item.</p>\\n</li>\\n<li data-end=\"1987\" data-start=\"1886\">\\n<p data-end=\"1987\" data-start=\"1888\"><strong data-end=\"1899\" data-start=\"1888\">Output:</strong> A probability score that represents how likely the user is to interact with the item.</p>\\n</li>\\n</ul>\\n<p data-end=\"2043\" data-start=\"1989\">The difficulty comes with negative examples (not just whether a user has watched a video - but when a user HAS NOT watched a video)</p>\\n<hr data-end=\"2255\" data-start=\"2252\" />\\n<p data-end=\"2406\" data-start=\"2257\">This creates a <strong data-end=\"2289\" data-start=\"2272\">feedback loop</strong>: the more you interact, the more training data the system gets, which makes future predictions even more accurate.</p></div><p style=\"text-align: left;\"></p><h3 style=\"text-align: left;\">How it ties together</h3><p style=\"text-align: left;\">Offline, the <b>two-tower model</b> pre-encodes all the items (videos, etc.) and they are stored within a vector database.</p>Upon inference, the same <b>two-tower model</b> will encode the user using multiple user features, think: age, history, demographics, context, etc. This embedding is then used to fetch the closest item candidates via ANN. Both the user and the related items live in the same vector space, so dot product indicates similarity.<p></p><p style=\"text-align: left;\">The ANN retrieval returns <strong data-end=\"969\" data-start=\"936\">hundreds to tens of thousands</strong> of candidates, depending on the platform of course. Youtube will likely retrieve in the 200 to 500 range, while TikTok is likely to fetch numbers in the thousands. There is then a quick filtering system checking for things like repeated videos (where the user has already watched it).&nbsp;</p><p style=\"text-align: left;\">Thereafter, the <b>ranking model</b> is employed.&nbsp;</p><blockquote style=\"border: none; margin: 0 0 0 40px; padding: 0px;\"><p style=\"text-align: left;\"><b>Input</b>: <i>user features</i> + <i>item features</i> + <i>embeddings</i> + <i>interaction features</i> (more detailed features are used here as compared to the initial embedding)</p></blockquote><blockquote style=\"border: none; margin: 0 0 0 40px; padding: 0px;\"><p style=\"text-align: left;\"><b>Output</b>: a <i>probability</i> (e.g., <code data-end=\"1461\" data-start=\"1429\">P(click | user, item, context)</code>) or expected value (e.g., expected watch time, revenue, etc.).</p></blockquote><p>&nbsp;The candidates are then sorted in descending score order, and returned to the user.</p><p style=\"text-align: left;\"><br /></p><p></p><div style=\"text-align: left;\"><div><br /></div></div><div><br /><br /><br /></div>'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogger_crawler.parse_post(blogs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf61faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OBLJudge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
