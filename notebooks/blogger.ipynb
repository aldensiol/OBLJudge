{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "297360f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c5bbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aldensio/Desktop/Projects/OBLJudge\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24bb1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tools import BloggerCrawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dc7b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "blogger_crawler = BloggerCrawler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "448bcd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "blogs = blogger_crawler.get_all_posts(\"8343013142987416238\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba20c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Search and Recommendation at Scale - How does it work?',\n",
       "  'published': '2025-08-25T23:36:00-07:00',\n",
       "  'updated': '2025-08-28T23:19:43-07:00',\n",
       "  'content': '<h3 style=\"text-align: justify;\">Introduction&nbsp;</h3><div style=\"text-align: justify;\"><p data-end=\"571\" data-start=\"340\">If you\\'re a \"doom-scroller\" like me, I\\'m sure you\\'ve wondered to yourself, <em data-end=\"463\" data-start=\"415\">\"how does the TikTok algorithm actually work?\"</em> or <em data-end=\"529\" data-start=\"467\">\"why does it feel so personal to my tastes and preferences?\"</em> This blog aims to address exactly that.</p>\\n<p data-end=\"938\" data-start=\"573\">I’ll walk through some of the fundamental concepts behind recommendation systems, provide a high-level overview of each component, and then show how they come together to form the algorithms we all interact with daily. By the end, you should have a clearer sense of how platforms like TikTok, YouTube, or Netflix serve you exactly what you didn’t know you wanted.</p></div><div><h3 style=\"text-align: justify;\">Concepts</h3></div><h4 style=\"text-align: justify;\">Embedding Models</h4><div><p data-end=\"1189\" data-start=\"983\" style=\"text-align: justify;\">First and foremost, we need to understand <strong data-end=\"1059\" data-start=\"1025\">how machines understand things</strong>. When it comes to items, videos, or user behaviour, machines don’t see texts, colours, or emotions. They only understand numbers.</p>\\n<p data-end=\"1608\" data-start=\"1191\" style=\"text-align: justify;\">This is where <strong data-end=\"1225\" data-start=\"1205\">embedding models</strong> come in. An embedding model takes something complex (like the description of a video or a user’s watch history) and represents it as a vector--essentially, a list of numbers in a high-dimensional space. The magic lies in how these numbers capture relationships. For instance, these 4 words can be modelled into vectors: \"king\", \"queen\", \"man\", and \"woman\". Within the vector space that you have built, the distance between the words \"man\" and \"woman\" should be similar to the distance between the words \"king\" and \"queen\". In the same vein, 2 videos about cooking might end up “closer” in vector space than a cooking video and a gaming video.</p><p data-end=\"1608\" data-start=\"1191\" style=\"text-align: justify;\">This is to say, the distance between any 2 vectors represent how similar they are in meaning or context.</p>\\n<p data-end=\"1777\" data-start=\"1610\" style=\"text-align: justify;\">In simpler terms: embeddings are the language that allows recommendation systems to measure similarity and preference in a way that machines can compute efficiently.</p></div><h4 style=\"text-align: justify;\">Vector Databases</h4><div><p data-end=\"1942\" data-start=\"1807\" style=\"text-align: justify;\">Now that everything is represented as vectors, we need a way to store and search through them quickly.&nbsp;</p>\\n<p data-end=\"2265\" data-start=\"1944\" style=\"text-align: justify;\">A vector database is optimised to handle operations like “find me the most similar items to this cat video” at scale. Instead of scanning billions of items one by one, these databases use clever indexing structures (such as approximate nearest neighbour search or <i>ANN</i> for short) to retrieve the most relevant <i>candidates</i> (<i>answers</i>) in milliseconds.</p>\\n<p data-end=\"2540\" data-start=\"2267\" style=\"text-align: justify;\">Think of it like this: if embeddings are the words, the vector database is the dictionary that lets the system look things up. This step is crucial for scalability, since modern recommendation engines deal with massive catalogs of content and millions/billions of users.</p></div><h4 style=\"text-align: justify;\">Retrieval and Ranking Models</h4><div><p data-end=\"2806\" data-start=\"2582\">Once we have a pool of candidates retrieved from the vector database, the system still needs to decide <em data-end=\"2692\" data-start=\"2685\">which</em> items are most likely to capture your attention. This is where <strong data-end=\"2788\" data-start=\"2756\">retrieval and ranking models</strong> come into play.</p>\\n<ul data-end=\"3299\" data-start=\"2808\">\\n<li data-end=\"3040\" data-start=\"2808\">\\n<p data-end=\"3040\" data-start=\"2810\"><strong data-end=\"2830\" data-start=\"2810\">Retrieval models</strong> narrow down the huge universe of possible items into a smaller, more manageable set (say, from billions to a few thousand). They rely on embeddings and similarity to select items that are generally relevant.</p>\\n</li>\\n<li data-end=\"3299\" data-start=\"3041\">\\n<p data-end=\"3299\" data-start=\"3043\"><strong data-end=\"3061\" data-start=\"3043\">Ranking models</strong> then take this candidate set and re-order it with finer granularity. They incorporate additional <i>signals</i>, or <i>features</i>&nbsp;that <b>YOU</b> display: how long you watch, what you skip, your interactions, trending topics, even temporal context (what time of day you’re scrolling).</p>\\n</li>\\n</ul>\\n<p data-end=\"3473\" data-start=\"3301\">This two-stage process ensures that the system is both <strong data-end=\"3369\" data-start=\"3356\">efficient</strong> (retrieving candidates fast) and <strong data-end=\"3419\" data-start=\"3403\">personalised</strong> (ranking them in a way that feels tailored to you).</p></div><h3 style=\"text-align: justify;\">Architecture</h3><h3 style=\"text-align: justify;\"><br /><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEi6u-a2GAdQ4VGYtE8pthy4wTh-UEXZhUL_ijpfHg4bEWLp2KAuzDhLTx76r4k0eE5OrziwR3wAzhCIlzoSc6YEM2vlu3hn4VSLrer7ZxLlNUc7ivK7WB45BfAz90u8PoLP4yWzEiGeWghOJCjCb_3ULf8hLOFWn5kzlukDBv_ko8PdGjteOxlZbiN8ca_p\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"740\" data-original-width=\"1910\" height=\"248\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEi6u-a2GAdQ4VGYtE8pthy4wTh-UEXZhUL_ijpfHg4bEWLp2KAuzDhLTx76r4k0eE5OrziwR3wAzhCIlzoSc6YEM2vlu3hn4VSLrer7ZxLlNUc7ivK7WB45BfAz90u8PoLP4yWzEiGeWghOJCjCb_3ULf8hLOFWn5kzlukDBv_ko8PdGjteOxlZbiN8ca_p=w640-h248\" width=\"640\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><span style=\"font-weight: 400;\">Full Architecture</span></div></h3><h4 style=\"text-align: left;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEiUq2KslheNRPOKuc3bqAdZQRmDgLA6X_0dDTzpAgLrSEvg9-LUq9Ryp8JEm-GU16M1831ARYl-pC0_YKURB5OXrZl9P27yO1eSKvdcKgdCYEm-Y9OkHtgXevenKpMdHhVqckiKCa3H2Vbz5ePxvpDdP7zDlSoVs_Y6CACZnLIuqLn_BYb3UDokvGPYSqIC\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"736\" data-original-width=\"1780\" height=\"264\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEiUq2KslheNRPOKuc3bqAdZQRmDgLA6X_0dDTzpAgLrSEvg9-LUq9Ryp8JEm-GU16M1831ARYl-pC0_YKURB5OXrZl9P27yO1eSKvdcKgdCYEm-Y9OkHtgXevenKpMdHhVqckiKCa3H2Vbz5ePxvpDdP7zDlSoVs_Y6CACZnLIuqLn_BYb3UDokvGPYSqIC=w640-h264\" width=\"640\" /></a></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><span style=\"font-weight: normal;\">Feature Store</span></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><br /></div><div class=\"separator\" style=\"clear: both; text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEh18SEZxnffNqdf2R7iXHSAbxWDgo3ZXlwPs7pORtXqbgQluCEvnJOVTCqyQVssee39SRgWX-0oIyMo8z0orPjMfFKhKI6NOtJn1A4YSCKFM-iHOhi1QVyIeevxd7aA1vC-ifkCtfOhdRxqZLk5pjHuvzlDbRxKSHD77-wvS9L_TQamg12grBJ45-2DrCmW\" style=\"margin-left: 1em; margin-right: 1em;\"><img alt=\"\" data-original-height=\"706\" data-original-width=\"1746\" height=\"258\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEh18SEZxnffNqdf2R7iXHSAbxWDgo3ZXlwPs7pORtXqbgQluCEvnJOVTCqyQVssee39SRgWX-0oIyMo8z0orPjMfFKhKI6NOtJn1A4YSCKFM-iHOhi1QVyIeevxd7aA1vC-ifkCtfOhdRxqZLk5pjHuvzlDbRxKSHD77-wvS9L_TQamg12grBJ45-2DrCmW=w640-h258\" width=\"640\" /></a></div><span style=\"font-weight: 400;\">Two-Tower Model</span><br /><br /></div></h4><div><h4 style=\"text-align: left;\">Embedding Models (training perspective)</h4><p data-end=\"525\" data-start=\"340\">The embedding model is often jointly trained to map the <strong data-end=\"412\" data-start=\"396\">“user-space”</strong> into the <strong data-end=\"438\" data-start=\"422\">“item-space”</strong> using what’s called a <strong data-end=\"480\" data-start=\"461\">two-tower model</strong> (sometimes referred to as a dual encoder).</p>\\n<ul data-end=\"749\" data-start=\"527\">\\n<li data-end=\"627\" data-start=\"527\">\\n<p data-end=\"627\" data-start=\"529\">One tower encodes the <strong data-end=\"559\" data-start=\"551\">user</strong>: their watch history, likes, clicks, or other behavioral signals.</p>\\n</li>\\n<li data-end=\"749\" data-start=\"628\">\\n<p data-end=\"749\" data-start=\"630\">The other tower encodes the <strong data-end=\"666\" data-start=\"658\">item</strong>: a video, or product, represented by its metadata and content features.</p>\\n</li>\\n</ul>\\n<p data-end=\"948\" data-start=\"751\">Both towers output vectors in the same high-dimensional space. The goal is simple: if User A likes cat videos, then User A’s vector should end up <strong data-end=\"909\" data-start=\"897\">close to</strong> the vector representing a cat video.</p><p data-end=\"991\" data-start=\"950\">The loss function can be thought of as:</p><blockquote data-end=\"1165\" data-start=\"992\">\\n<p data-end=\"1165\" data-start=\"994\">“User A watched a cat video, so let’s pull User A’s vector closer to the cat video’s vector in the embedding space, while pushing it further away from unrelated videos.”</p></blockquote></div><div><h4 style=\"text-align: left;\">Ranking Models (training perspective)</h4>\\n<p data-end=\"1586\" data-start=\"1357\"></p></div><div><p data-end=\"1586\" data-start=\"1357\">Unlike the embedding model, the ranking model is trained in a <strong data-end=\"1565\" data-start=\"1536\">supervised learning setup</strong> with labeled data.</p>\\n<ul data-end=\"1987\" data-start=\"1588\">\\n<li data-end=\"1754\" data-start=\"1588\">\\n<p data-end=\"1754\" data-start=\"1590\"><strong data-end=\"1600\" data-start=\"1590\">Input:</strong> A candidate user-item pair (e.g., “User A and Video X”), along with contextual features like time of day, device type, or whether the item is trending.</p>\\n</li>\\n<li data-end=\"1885\" data-start=\"1755\">\\n<p data-end=\"1885\" data-start=\"1757\"><strong data-end=\"1767\" data-start=\"1757\">Label:</strong> The ground truth engagement signal, such as whether the user actually clicked, watched, how long he watched, liked, or skipped the item.</p>\\n</li>\\n<li data-end=\"1987\" data-start=\"1886\">\\n<p data-end=\"1987\" data-start=\"1888\"><strong data-end=\"1899\" data-start=\"1888\">Output:</strong> A probability score that represents how likely the user is to interact with the item.</p>\\n</li>\\n</ul>\\n<p data-end=\"2043\" data-start=\"1989\">The difficulty comes with negative examples (not just whether a user has watched a video - but when a user HAS NOT watched a video)</p>\\n<hr data-end=\"2255\" data-start=\"2252\" />\\n<p data-end=\"2406\" data-start=\"2257\">This creates a <strong data-end=\"2289\" data-start=\"2272\">feedback loop</strong>: the more you interact, the more training data the system gets, which makes future predictions even more accurate.</p></div><p style=\"text-align: left;\"></p><h3 style=\"text-align: left;\">How it ties together</h3><p style=\"text-align: left;\">Offline, the <b>two-tower model</b> pre-encodes all the items (videos, etc.) and they are stored within a vector database.</p>Upon inference, the same <b>two-tower model</b> will encode the user using multiple user features, think: age, history, demographics, context, etc. This embedding is then used to fetch the closest item candidates via ANN. Both the user and the related items live in the same vector space, so dot product indicates similarity.<p></p><p style=\"text-align: left;\">The ANN retrieval returns <strong data-end=\"969\" data-start=\"936\">hundreds to tens of thousands</strong> of candidates, depending on the platform of course. Youtube will likely retrieve in the 200 to 500 range, while TikTok is likely to fetch numbers in the thousands. There is then a quick filtering system checking for things like repeated videos (where the user has already watched it).&nbsp;</p><p style=\"text-align: left;\">Thereafter, the <b>ranking model</b> is employed.&nbsp;</p><blockquote style=\"border: none; margin: 0 0 0 40px; padding: 0px;\"><p style=\"text-align: left;\"><b>Input</b>: <i>user features</i> + <i>item features</i> + <i>embeddings</i> + <i>interaction features</i> (more detailed features are used here as compared to the initial embedding)</p></blockquote><blockquote style=\"border: none; margin: 0 0 0 40px; padding: 0px;\"><p style=\"text-align: left;\"><b>Output</b>: a <i>probability</i> (e.g., <code data-end=\"1461\" data-start=\"1429\">P(click | user, item, context)</code>) or expected value (e.g., expected watch time, revenue, etc.).</p></blockquote><p>&nbsp;The candidates are then sorted in descending score order, and returned to the user.</p><p style=\"text-align: left;\"><br /></p><p></p><div style=\"text-align: left;\"><div><br /></div></div><div><br /><br /><br /></div>',\n",
       "  'outbound_links': ['https://blogger.googleusercontent.com/img/a/AVvXsEi6u-a2GAdQ4VGYtE8pthy4wTh-UEXZhUL_ijpfHg4bEWLp2KAuzDhLTx76r4k0eE5OrziwR3wAzhCIlzoSc6YEM2vlu3hn4VSLrer7ZxLlNUc7ivK7WB45BfAz90u8PoLP4yWzEiGeWghOJCjCb_3ULf8hLOFWn5kzlukDBv_ko8PdGjteOxlZbiN8ca_p',\n",
       "   'https://blogger.googleusercontent.com/img/a/AVvXsEiUq2KslheNRPOKuc3bqAdZQRmDgLA6X_0dDTzpAgLrSEvg9-LUq9Ryp8JEm-GU16M1831ARYl-pC0_YKURB5OXrZl9P27yO1eSKvdcKgdCYEm-Y9OkHtgXevenKpMdHhVqckiKCa3H2Vbz5ePxvpDdP7zDlSoVs_Y6CACZnLIuqLn_BYb3UDokvGPYSqIC',\n",
       "   'https://blogger.googleusercontent.com/img/a/AVvXsEh18SEZxnffNqdf2R7iXHSAbxWDgo3ZXlwPs7pORtXqbgQluCEvnJOVTCqyQVssee39SRgWX-0oIyMo8z0orPjMfFKhKI6NOtJn1A4YSCKFM-iHOhi1QVyIeevxd7aA1vC-ifkCtfOhdRxqZLk5pjHuvzlDbRxKSHD77-wvS9L_TQamg12grBJ45-2DrCmW']},\n",
       " {'title': 'Modern Architectures for Recommendation Systems',\n",
       "  'published': '2025-08-25T00:44:00-07:00',\n",
       "  'updated': '2025-08-29T00:06:06-07:00',\n",
       "  'content': '<h1>Modern Architectures for Recommender Systems: When AI Gets Really Good at Knowing What You Want</h1>\\n<p>Remember the last time Spotify served up that perfect playlist that made your commute actually enjoyable? That\\'s the magic of modern recommender systems at work, and boy, have they gotten sophisticated lately.</p>\\n<p>Today, we\\'re diving into some cutting-edge approaches that are revolutionising how these systems understand and predict our preferences.&nbsp;</p>\\n<h2>The Challenge: Teaching Machines to Read Our Minds (Sort Of)</h2>\\n<p>Here\\'s the thing about building great recommender systems: it\\'s like trying to understand someone\\'s taste in movies based on their Netflix history, except you\\'re doing this for millions of people simultaneously, and you need to be right most of the time. No pressure, right?</p>\\n<p>Traditional approaches have worked well enough, but they\\'ve hit some walls. The biggest headache? Getting enough labeled data (especially negative labels) to train these systems properly. It\\'s like trying to learn a language when most of the books have their pages torn out. You can make some progress, but you\\'re definitely missing the full picture.</p>\\n<h2>Enter Self-Supervised Learning: The Art of Learning Without a Teacher</h2>\\n<p>This is where things get really interesting. Researchers have figured out how to make these systems learn from unlabelled data using something called self-supervised learning. It\\'s like teaching someone to recognise good music by having them listen to tons of songs without telling them what\\'s good or bad, and somehow they figure it out on their own.</p>\\n<p>One particularly clever approach takes inspiration from something called Barlow Twins (originally designed for computer vision) and adapts it for understanding user behaviour sequences. The basic idea is brilliantly simple: take a user\\'s interaction history, create two slightly different versions of it, and teach the model to understand that these versions should be fundamentally similar despite the surface-level differences.</p>\\n<h3>The Secret Sauce: Data Augmentation for User Behaviour</h3>\\n<p>The researchers tried three different ways to create these \"slightly different\" versions:</p>\\n<p><strong>Random Masking</strong>: Imagine taking someone\\'s movie-watching history and randomly hiding some titles. It\\'ll look something like this: \"Let\\'s see... you watched The Office, [HIDDEN], Stranger Things, [HIDDEN], The Crown...\" The model learns to fill in these gaps by understanding patterns in viewing behaviour.</p>\\n<p><strong>Segment Masking</strong>: Instead of hiding random movies, this approach hides entire chunks of viewing history. It\\'s like saying \"you binged these shows last weekend, but I\\'m not telling you which ones.\" This forces the model to understand longer-term patterns and preferences.</p>\\n<p><strong>Permutation</strong>: This one shuffles the order of interactions, which might sound crazy, but it actually helps the model focus on what someone watched rather than when they watched it.</p>\\n<p>Interestingly, segment masking turned out to be the winner. There\\'s something about forcing the model to understand contiguous patterns of behaviour that makes it better at predicting what users might want next.</p>\\n<h2>Going Generative: When Recommendation Becomes a Conversation</h2>\\n<p>While self-supervised learning is making waves, another fascinating approach is treating recommendation as a generative task. Instead of just scoring items, these systems actually \"generate\" recommendations by predicting sequences of user actions, hence the term: generative recommendation.</p>\\n<p>Think of it like this: traditional systems might say \"this user has a 73% chance of clicking this video.\" Generative systems, on the other hand, construct a kind of narrative: \"Based on this user\\'s morning routine of checking work emails, they\\'ll probably want some upbeat music, followed by a productivity podcast, then maybe some news articles.\"</p>\\n<h3>The Industrial Reality Check</h3>\\n<p>Of course, building these systems for real-world applications (like Xiaohongshu\\'s Explore Feed serving hundreds of millions of users) means dealing with some serious engineering challenges. The researchers discovered something crucial: the magic isn\\'t just in the training approach, but in the architecture itself.</p>\\n<p>They introduced GenRank, a clever architecture that treats items as positional information and focuses on predicting user actions. It\\'s like switching from asking \"what item comes next?\" to \"what will the user do next with this item?\" This small change cuts computational costs dramatically while maintaining performance.</p>\\n<h3>The Need for Speed</h3>\\n<p>One of the coolest aspects of GenRank is how it handles the computational bottlenecks that plague large-scale systems. Traditional approaches often get bogged down in quadratic complexity (meaning that processing time increases exponentially with sequence length). GenRank introduces some clever tricks:</p>\\n<ul>\\n<li><strong>Action-oriented organization</strong>: Instead of doubling sequence length by tracking both items and actions separately, it combines them intelligently</li>\\n<li><strong>Efficient position encoding</strong>: Rather than expensive attention mechanisms, it uses lightweight embeddings that capture temporal patterns without the computational overhead</li>\\n</ul>\\n<p>The result? A 94.8% speed-up during training with comparable or better performance.</p>\\n<h2>What This Means for Your Daily Digital Life</h2>\\n<p>These advances aren\\'t just academic exercises. They\\'re already showing up in real products:</p>\\n<ul>\\n<li><strong>Better cold-start performance</strong>: When you\\'re new to a platform, these systems get good at recommending things much faster</li>\\n<li><strong>More nuanced understanding</strong>: Instead of just \"you liked action movies,\" the system understands patterns like \"you watch comedies on Friday nights but prefer documentaries on Sunday afternoons\"</li>\\n<li><strong>Improved efficiency</strong>: Faster systems mean more responsive apps and better user experiences</li>\\n</ul>\\n<p>The online experiments with GenRank showed improvements across the board: users spent more time engaged, read more content, and had higher lifetime value. Most importantly, the system got particularly good at surfacing relevant content for newer items, which is notoriously difficult in recommendation systems.</p>\\n<h2>The Road Ahead: What\\'s Next in Recommendation Land?</h2>\\n<p>These developments point toward some exciting possibilities:</p>\\n<p><strong>Unified Architectures</strong>: We might see systems that handle retrieval, ranking, and re-ranking in a single, coherent framework rather than the current multi-stage pipelines.</p>\\n<p><strong>Foundation Models for Recommendation</strong>: Just as GPT transformed language tasks, we could see large, pre-trained models that understand user behaviour patterns across different domains and platforms.</p>\\n<p><strong>Real-time Adaptation</strong>: Systems that adjust to your changing preferences throughout the day, understanding context like time, location, and recent activities.</p>\\n<p><strong>Privacy-Preserving Personalisation</strong>: Self-supervised approaches are particularly promising for learning from user data without requiring explicit labels, which could enable better privacy protection.</p>\\n<h2>The Bigger Picture</h2>\\n<p>What\\'s fascinating about these advances is how they mirror broader trends in AI. The shift toward self-supervised learning, the focus on efficiency and scalability, and the move toward more generative approaches are happening across the field. Recommender systems are becoming a testing ground for ideas that eventually influence everything from search engines to conversational AI.</p>\\n<p>The next time your streaming service nail that perfect recommendation or your social feed serves up exactly what you were in the mood for, remember there\\'s some seriously sophisticated technology working behind the scenes. These systems are getting scary good at understanding human preferences, and honestly, that\\'s both exciting and slightly unnerving.</p>\\n<p>But hey, at least they\\'re helping us discover great content along the way. Now, if only they could recommend what to make for dinner...</p>\\n<hr />\\n<p><em>The research discussed here represents work from teams at Cornell University, Google Research, Google DeepMind, and Xiaohongshu. The full papers provide much more technical detail for those interested in diving deeper into the architectures and methodologies.</em></p>',\n",
       "  'outbound_links': []}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf61faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OBLJudge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
